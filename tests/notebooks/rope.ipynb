{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "source": [
    "import rope.base.project\n",
    "from rope.refactor.extract import ExtractMethod\n",
    "from rope.refactor.inline import InlineMethod\n",
    "import re\n",
    "\n",
    "APOSTROPHE_MARKER = \"__APOSTROPHE__\"\n",
    "PERCENT_FORMAT_MARKER = \"__PERCENT_FORMAT__\"\n",
    "\n",
    "def serialize(text: str):\n",
    "    # Replace \"'{var}'\" with \"__APOSTROPHE__{var}__APOSTROPHE__\"\n",
    "    text = re.sub(r\"'{([^'}]*?)}'\", f\"{APOSTROPHE_MARKER}{{\\\\1}}{APOSTROPHE_MARKER}\", text)\n",
    "    # Replace \"%s\" with \"__PERCENT_FORMAT__\"\n",
    "    text = re.sub(r\"%\\((.*?)\\)s\", f\"{PERCENT_FORMAT_MARKER}{{\\\\1}}\", text)\n",
    "    return text\n",
    "\n",
    "def deserialize(text: str):\n",
    "    text = re.sub(f\"{APOSTROPHE_MARKER}{{(.*?)}}{APOSTROPHE_MARKER}\", \"'{\\\\1}'\", text)\n",
    "    text = re.sub(f\"{PERCENT_FORMAT_MARKER}{{(.*?)}}\", \"%(\\\\1)s\", text)\n",
    "    return text\n",
    "\n",
    "myproject = rope.base.project.Project('src')\n",
    "\n",
    "myresource = myproject.get_resource('test.py')\n",
    "contents = myresource.read()\n",
    "print(contents)\n",
    "serialized_contents = serialize(myresource.read())\n",
    "myresource.write(serialized_contents)\n",
    "extract_span = r\"\"\"new_function_names = []\n",
    "        existing_names = \", \".join(\n",
    "            [def_fn.name.strip(\"'\") for def_fn in all_defined_functions]\n",
    "        )\n",
    "        offset = 5\n",
    "        for idx in range(0, len(deduped_exact_matches), offset):\n",
    "            num_snippets = min(len(deduped_exact_matches), idx + offset) - idx\n",
    "            formatted_snippets = \"\\n\".join(\n",
    "                [\n",
    "                    f\"<function_to_name>\\n{snippet}\\n</function_to_name>\"\n",
    "                    for snippet in deduped_exact_matches[idx:idx+num_snippets]\n",
    "                ]\n",
    "            )\n",
    "            new_function_names.extend(NameBot(chat_logger=self.chat_logger).name_functions(\n",
    "                old_code=cloned_repo.get_file_contents(file_path),\n",
    "                snippets=formatted_snippets,\n",
    "                existing_names=existing_names,\n",
    "                count=num_snippets,\n",
    "            ))\n",
    "        for idx, extracted_original_code in enumerate(deduped_exact_matches):\n",
    "            if idx >= len(new_function_names):\n",
    "                break\"\"\"\n",
    "serialized_extract_span = serialize(extract_span)\n",
    "print(serialized_extract_span)\n",
    "\n",
    "start, end = serialized_contents.find(serialized_extract_span), serialized_contents.find(serialized_extract_span) + len(serialized_extract_span)\n",
    "print(start, end)\n",
    "\n",
    "try:\n",
    "    extractor = ExtractMethod(myproject, myresource, start, end)\n",
    "    change_set = extractor.get_changes(\"helper\", similar=True)\n",
    "    for change in change_set.changes:\n",
    "        if change.old_contents is not None:\n",
    "            change.old_contents = deserialize(change.old_contents)\n",
    "        else:\n",
    "            change.old_contents = deserialize(change.resource.read())\n",
    "        change.new_contents = deserialize(change.new_contents)\n",
    "    for change in change_set.changes:\n",
    "        print(change.get_description())\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    raise e\n",
    "finally:\n",
    "    myresource.write(contents)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "myresource = myproject.get_resource('mod3.py')\n",
    "contents = myresource.read()\n",
    "serialized_contents = serialize(myresource.read())\n",
    "myresource.write(serialized_contents)\n",
    "extract_span = r\"\"\"                openai.api_type = OPENAI_API_TYPE\n",
    "                openai.api_base = OPENAI_API_BASE\n",
    "                openai.api_version = OPENAI_API_VERSION\n",
    "                openai.api_key = AZURE_API_KEY\n",
    "                response = openai.ChatCompletion.create(\n",
    "                    engine=engine,\n",
    "                    model=model,\n",
    "                    messages=messages,\n",
    "                    max_tokens=max_tokens,\n",
    "                    temperature=temperature,\n",
    "                    timeout=OPENAI_TIMEOUT,\n",
    "                )\"\"\"\n",
    "serialized_extract_span = serialize(extract_span)\n",
    "print(serialized_extract_span)\n",
    "\n",
    "start, end = serialized_contents.find(serialized_extract_span), serialized_contents.find(serialized_extract_span) + len(serialized_extract_span)\n",
    "print(start, end)\n",
    "\n",
    "try:\n",
    "    extractor = ExtractMethod(myproject, myresource, start, end)\n",
    "    change_set = extractor.get_changes(\"helper\", similar=True)\n",
    "    for change in change_set.changes:\n",
    "        if change.old_contents is not None:\n",
    "            change.old_contents = deserialize(change.old_contents)\n",
    "        else:\n",
    "            change.old_contents = deserialize(change.resource.read())\n",
    "        change.new_contents = deserialize(change.new_contents)\n",
    "    for change in change_set.changes:\n",
    "        print(change.get_description())\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "finally:\n",
    "    myresource.write(contents)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "source": [
    "len(change.new_contents) - len(change.old_contents)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "source": [
    "myproject = rope.base.project.Project('./src')\n",
    "mod1 = myproject.get_resource('mod3.py')\n",
    "mod1.write(r\"\"\"\n",
    "class OpenAIProxy:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    @file_cache(ignore_params=[])\n",
    "    def call_openai(self, model, messages, max_tokens, temperature) -> str:\n",
    "        try:\n",
    "            engine = None\n",
    "            if model in OPENAI_EXCLUSIVE_MODELS and OPENAI_API_TYPE != \"azure\":\n",
    "                logger.info(f\"Calling OpenAI exclusive model. {model}\")\n",
    "                raise Exception(\"OpenAI exclusive model.\")\n",
    "            if (\n",
    "                model == \"gpt-3.5-turbo-16k\"\n",
    "                or model == \"gpt-3.5-turbo-16k-0613\"\n",
    "                and OPENAI_API_ENGINE_GPT35 is not None\n",
    "            ):\n",
    "                engine = OPENAI_API_ENGINE_GPT35\n",
    "            elif (\n",
    "                model == \"gpt-4\"\n",
    "                or model == \"gpt-4-0613\"\n",
    "                and OPENAI_API_ENGINE_GPT4 is not None\n",
    "            ):\n",
    "                engine = OPENAI_API_ENGINE_GPT4\n",
    "            elif (\n",
    "                model == \"gpt-4-32k\"\n",
    "                or model == \"gpt-4-32k-0613\"\n",
    "                and OPENAI_API_ENGINE_GPT4_32K is not None\n",
    "            ):\n",
    "                engine = OPENAI_API_ENGINE_GPT4_32K\n",
    "            if OPENAI_API_TYPE is None or engine is None:\n",
    "                openai.api_key = OPENAI_API_KEY\n",
    "                openai.api_base = \"https://api.openai.com/v1\"\n",
    "                openai.api_version = None\n",
    "                openai.api_type = \"open_ai\"\n",
    "                response = openai.ChatCompletion.create(\n",
    "                    model=model,\n",
    "                    messages=messages,\n",
    "                    max_tokens=max_tokens,\n",
    "                    temperature=temperature,\n",
    "                    timeout=OPENAI_TIMEOUT,\n",
    "                    seed=SEED,\n",
    "                )\n",
    "                return response[\"choices\"][0].message.content\n",
    "            # validity checks for MULTI_REGION_CONFIG\n",
    "            if (\n",
    "                MULTI_REGION_CONFIG is None\n",
    "                or not isinstance(MULTI_REGION_CONFIG, list)\n",
    "                or len(MULTI_REGION_CONFIG) == 0\n",
    "                or not isinstance(MULTI_REGION_CONFIG[0], list)\n",
    "            ):\n",
    "                logger.info(\n",
    "                    f\"Calling {model} with engine {engine} on Azure url {OPENAI_API_BASE}.\"\n",
    "                )\n",
    "                openai.api_type = OPENAI_API_TYPE\n",
    "                openai.api_base = OPENAI_API_BASE\n",
    "                openai.api_version = OPENAI_API_VERSION\n",
    "                openai.api_key = AZURE_API_KEY\n",
    "                response = openai.ChatCompletion.create(\n",
    "                    engine=engine,\n",
    "                    model=model,\n",
    "                    messages=messages,\n",
    "                    max_tokens=max_tokens,\n",
    "                    temperature=temperature,\n",
    "                    timeout=OPENAI_TIMEOUT,\n",
    "                )\n",
    "                return response[\"choices\"][0].message.content\n",
    "            # multi region config is a list of tuples of (region_url, api_key)\n",
    "            # we will try each region in order until we get a response\n",
    "            # randomize the order of the list\n",
    "            SHUFFLED_MULTI_REGION_CONFIG = random.sample(\n",
    "                MULTI_REGION_CONFIG, len(MULTI_REGION_CONFIG)\n",
    "            )\n",
    "            for region_url, api_key in SHUFFLED_MULTI_REGION_CONFIG:\n",
    "                try:\n",
    "                    logger.info(\n",
    "                        f\"Calling {model} with engine {engine} on Azure url {region_url}.\"\n",
    "                    )\n",
    "                    openai.api_key = api_key\n",
    "                    openai.api_base = region_url\n",
    "                    openai.api_version = OPENAI_API_VERSION\n",
    "                    openai.api_type = OPENAI_API_TYPE\n",
    "                    response = openai.ChatCompletion.create(\n",
    "                        engine=engine,\n",
    "                        model=model,\n",
    "                        messages=messages,\n",
    "                        max_tokens=max_tokens,\n",
    "                        temperature=temperature,\n",
    "                        timeout=OPENAI_TIMEOUT,\n",
    "                    )\n",
    "                    return response[\"choices\"][0].message.content\n",
    "                except SystemExit:\n",
    "                    raise SystemExit\n",
    "                except Exception as e:\n",
    "                    logger.exception(f\"Error calling {region_url}: {e}\")\n",
    "            raise Exception(\"No Azure regions available\")\n",
    "        except SystemExit:\n",
    "            raise SystemExit\n",
    "        except Exception as e:\n",
    "            if OPENAI_API_KEY:\n",
    "                try:\n",
    "                    openai.api_key = OPENAI_API_KEY\n",
    "                    openai.api_base = \"https://api.openai.com/v1\"\n",
    "                    openai.api_version = None\n",
    "                    openai.api_type = \"open_ai\"\n",
    "                    response = openai.ChatCompletion.create(\n",
    "                        model=model,\n",
    "                        messages=messages,\n",
    "                        max_tokens=max_tokens,\n",
    "                        temperature=temperature,\n",
    "                        timeout=OPENAI_TIMEOUT,\n",
    "                        seed=SEED,\n",
    "                    )\n",
    "                    return response[\"choices\"][0].message.content\n",
    "                except SystemExit:\n",
    "                    raise SystemExit\n",
    "                except Exception as _e:\n",
    "                    logger.error(f\"OpenAI API Key found but error: {_e}\")\n",
    "            logger.error(f\"OpenAI API Key not found and Azure Error: {e}\")\n",
    "            # Raise exception to report error\n",
    "            raise e\n",
    "\"\"\")\n",
    "\n",
    "from rope.refactor import restructure\n",
    "pattern = r\"\"\"\n",
    "openai.api_key = ${api_key}\n",
    "openai.api_base = ${api_base}\n",
    "openai.api_version = ${api_version}\n",
    "openai.api_type = ${api_type}\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=${model},\n",
    "    messages=${messages},\n",
    "    max_tokens=${max_tokens},\n",
    "    temperature=${temperature},\n",
    "    timeout=${timeout},\n",
    "    seed=${seed},\n",
    ")\"\"\"\n",
    "goal = \"\"\"print(\n",
    "    ${api_key},\n",
    "    ${api_base},\n",
    "    ${api_version},\n",
    "    ${api_type},\n",
    "    ${model},\n",
    "    ${messages},\n",
    "    ${max_tokens},\n",
    "    ${temperature},\n",
    "    ${timeout},\n",
    "    ${seed},\n",
    ")\"\"\"\n",
    "\n",
    "restructuring = restructure.Restructure(myproject, pattern, goal)\n",
    "print(restructuring.get_changes().get_description())"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "source": [
    "from rope.refactor import usefunction\n",
    "\n",
    "sweep_project = rope.base.project.Project('../../sweepai', ignored_resources=[\"sandbox\"])\n",
    "resource = sweep_project.get_resource('utils/str_utils.py')\n",
    "# resource = sweep_project.get_resource('utils/openai_proxy.py')\n",
    "# start = resource.read().find('_call_openai')\n",
    "start = resource.read().find('entities_split')\n",
    "use_function = usefunction.UseFunction(sweep_project, resource, start)\n",
    "print(use_function.get_changes().get_description())"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "source": [
    "from rope.base.project import Project\n",
    "from rope.contrib.autoimport import AutoImport\n",
    "\n",
    "project = Project(\"../../sweepai\")\n",
    "autoimport = AutoImport(project)\n",
    "# autoimport.generate_resource_cache()  # Generates a cache of the local modules, from the project you're working on\n",
    "autoimport.generate_modules_cache([\"../../sweepai\", \".\"])  # Generates a cache of external modules\n",
    "print(autoimport.import_assist(\"sweepai\"))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.10 ('sweepai-u_CIt3kb-py3.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "25d341f3248a096a89b9dbf6eec8e41f63aed02f6ba059df22a49224e3e8f1b0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
