{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "source": [
    "from sweepai.config.client import SweepConfig\n",
    "from sweepai.core.lexical_search import prepare_lexical_search_index\n",
    "from sweepai.utils.github_utils import ClonedRepo, MockClonedRepo\n",
    "\n",
    "\n",
    "cloned_repo = MockClonedRepo(\n",
    "    \"/tmp/sweep\",\n",
    "    \"sweepai/sweep\",\n",
    ")\n",
    "\n",
    "_, snippets, lexical_index = prepare_lexical_search_index(\n",
    "    cloned_repo.cached_dir,\n",
    "    SweepConfig(),\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "source": [
    "from sweepai.core.lexical_search import SNIPPET_FORMAT\n",
    "from sweepai.core.vector_db import embed_text_array\n",
    "\n",
    "snippet_formats = [\n",
    "    SNIPPET_FORMAT.format(\n",
    "        file_path=snippet.file_path,\n",
    "        contents=snippet.get_snippet(add_ellipsis=False, add_lines=False),\n",
    "    ) for snippet in snippets\n",
    "]\n",
    "\n",
    "embeddings = embed_text_array(snippet_formats)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "\n",
    "embeddings = np.concatenate(embeddings, axis=0)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "source": [
    "embeddings, embeddings.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Clustering\n",
    "kmeans = KMeans(n_clusters=10, random_state=42)\n",
    "clusters = kmeans.fit_predict(embeddings)\n",
    "\n",
    "# Dimensionality Reduction\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "reduced_embeddings = tsne.fit_transform(embeddings)\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(reduced_embeddings[:, 0], reduced_embeddings[:, 1], c=clusters, cmap='viridis', alpha=0.6)\n",
    "plt.colorbar(scatter)\n",
    "plt.title('t-SNE visualization of Embeddings Clustered by K-Means')\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "source": [
    "cluster_indices = {}\n",
    "for i in range(kmeans.n_clusters):\n",
    "    cluster_indices[i] = np.where(clusters == i)[0]\n",
    "\n",
    "for cluster, indices in cluster_indices.items():\n",
    "    print(f\"Cluster {cluster}\")\n",
    "    count = 0\n",
    "    vis_file_path = set()\n",
    "    for index in indices:\n",
    "        if count == 20:\n",
    "            break\n",
    "        if snippets[index].file_path in vis_file_path:\n",
    "            continue\n",
    "        vis_file_path.add(snippets[index].file_path)\n",
    "        print(snippets[index].file_path.removeprefix(cloned_repo._repo_dir + \"/\"))\n",
    "        count += 1\n",
    "    print(\"\\n\")\n",
    "    "
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "source": [
    "import os\n",
    "\n",
    "def count_files(directory):\n",
    "    total_count = 0\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        total_count += len(files)\n",
    "    return total_count\n",
    "\n",
    "def find_large_subdirs(directory, file_threshold):\n",
    "    large_subdirs = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        if \".git\" in root.split(os.sep):\n",
    "            continue\n",
    "        subdir_file_count = count_files(root)\n",
    "        if subdir_file_count > file_threshold:\n",
    "            large_subdirs.append(root)\n",
    "    large_subdirs.remove(directory)\n",
    "    return large_subdirs\n",
    "\n",
    "\n",
    "# Usage: Specify the directory path and the file threshold\n",
    "directory_path = cloned_repo._repo_dir\n",
    "file_threshold = 10\n",
    "large_subdirectories = find_large_subdirs(directory_path, file_threshold)\n",
    "print(\"Subdirectories with more than 20 files:\", large_subdirectories)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "source": [
    "large_subdirectory = large_subdirectories[0]\n",
    "snippets_in_subdir = []\n",
    "embeddings_in_subdir = []\n",
    "\n",
    "for i, snippet in enumerate(snippets):\n",
    "    if snippet.file_path.startswith(large_subdirectory):\n",
    "        snippets_in_subdir.append(snippet)\n",
    "        embeddings_in_subdir.append(embeddings[i])\n",
    "\n",
    "print(snippets_in_subdir)\n",
    "print(embeddings_in_subdir)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "\n",
    "def select_diverse_vectors(vectors, num_vectors=5):\n",
    "    # Start with a random vector\n",
    "    selected_indices = [np.random.randint(len(vectors))]\n",
    "    selected_vectors = [vectors[selected_indices[0]]]\n",
    "    \n",
    "    for _ in range(1, num_vectors):\n",
    "        max_min_distance = 0\n",
    "        next_index = -1\n",
    "        \n",
    "        for i in range(len(vectors)):\n",
    "            if i in selected_indices:\n",
    "                continue\n",
    "            \n",
    "            # Calculate minimum distance to all selected vectors\n",
    "            distances = cosine_distances([vectors[i]], selected_vectors)[0]\n",
    "            min_distance = np.min(distances)\n",
    "            \n",
    "            # Select the vector that maximizes the minimum distance\n",
    "            if min_distance > max_min_distance:\n",
    "                max_min_distance = min_distance\n",
    "                next_index = i\n",
    "        \n",
    "        selected_indices.append(next_index)\n",
    "        selected_vectors.append(vectors[next_index])\n",
    "    \n",
    "    return selected_indices\n",
    "\n",
    "# Example usage\n",
    "# Assuming 'embeddings' is your list of embeddings\n",
    "indices = select_diverse_vectors(embeddings_in_subdir)\n",
    "diverse_snippets = [snippets_in_subdir[i] for i in indices]\n",
    "diverse_vectors = [embeddings_in_subdir[i] for i in indices]\n",
    "print(diverse_snippets)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "source": [
    "from sweepai.core.vector_db import cosine_similarity\n",
    "\n",
    "\n",
    "def find_central_vectors(vectors, num_vectors=5):\n",
    "    # Calculate the centroid of all vectors\n",
    "    centroid = np.mean(vectors, axis=0)\n",
    "    \n",
    "    # Compute cosine similarities between each vector and the centroid\n",
    "    similarities = cosine_similarity(vectors, [centroid]).flatten()\n",
    "    \n",
    "    # Get indices of the top 'num_vectors' vectors with highest similarity\n",
    "    central_indices = np.argsort(-similarities)[:num_vectors]\n",
    "    \n",
    "    return central_indices\n",
    "\n",
    "# Example usage\n",
    "# Assuming 'embeddings' is your list of embeddings\n",
    "central_indices = find_central_vectors(np.array(embeddings_in_subdir))\n",
    "central_snippets = [snippets[i] for i in central_indices]\n",
    "central_vectors = [embeddings[i] for i in central_indices]\n",
    "for snippet in central_snippets:\n",
    "    print(snippet.denotation + \"\\n\\n\")\n",
    "    print(snippet.get_snippet(False, False))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "source": [
    "def count_descendants(directory):\n",
    "    descendant_count = {}\n",
    "\n",
    "    def dfs(current_dir):\n",
    "        count = 0\n",
    "        for root, dirs, files in os.walk(current_dir):\n",
    "            if \".git\" in root.split(os.sep):\n",
    "                continue\n",
    "            for d in dirs:\n",
    "                if \".git\" in root.split(os.sep):\n",
    "                    continue\n",
    "                count += dfs(os.path.join(root, d))\n",
    "            count += len(files)\n",
    "        descendant_count[current_dir.removeprefix(directory.rstrip() + \"/\")] = count\n",
    "        return count\n",
    "\n",
    "    dfs(directory)\n",
    "    for key in (\".git\", \"\", directory):\n",
    "        if key in descendant_count:\n",
    "            del descendant_count[key]\n",
    "    return descendant_count\n",
    "\n",
    "directory_path = cloned_repo._repo_dir\n",
    "descendants = count_descendants(directory_path)\n",
    "print(descendants)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "source": [
    "def print_sorted_descendants(directory):\n",
    "    descendants = count_descendants(directory)\n",
    "    # Sort directories by the number of files, from highest to lowest\n",
    "    sorted_descendants = sorted(descendants.items(), key=lambda item: item[1], reverse=True)\n",
    "    for dir_path, count in sorted_descendants:\n",
    "        print(f\"{dir_path}: {count}\")\n",
    "print(\"Sorted descendants:\")\n",
    "print_sorted_descendants(directory_path)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "source": [
    "def plot_histogram(directory):\n",
    "    file_counts = count_descendants(directory)\n",
    "    values = list(file_counts.values())\n",
    "\n",
    "    bins = list(range(0, 101))  # Bins from 0 to 100\n",
    "    bins.append(max(values) + 1)  # Additional bin for all values greater than 100\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(values, bins=100, alpha=0.7, color='blue', edgecolor='black')\n",
    "    plt.title('Histogram of File Counts in Directories')\n",
    "    plt.xlabel('Number of Files')\n",
    "    plt.ylabel('Number of Directories')\n",
    "    plt.xlim(0, 100)\n",
    "    \n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "directory_path = cloned_repo._repo_dir\n",
    "plot_histogram(directory_path)"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
